{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_kaggle(1227).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc5f8MlB5VEg",
        "outputId": "4d2555f3-02c1-4994-fc53-f3d860910810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
        "!wget -q https://raw.githubusercontent.com/google-research/bert/master/optimization.py \n",
        "!wget -q https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py \n",
        "!wget -q https://raw.githubusercontent.com/google-research/bert/master/tokenization.py "
      ],
      "metadata": {
        "id": "clf627755d4d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 임포트\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import sys\n",
        "import zipfile\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import tokenization\n",
        " \n",
        "from tokenization import FullTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "import tensorflow_hub as hub\n",
        "from tqdm import tqdm_notebook\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdV89hcl53H8",
        "outputId": "7f48f001-a907-4bb7-9c31-c1d985daf8e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /content/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT모델과 tokenization의 파라미터 지정\n",
        "sess = tf.Session()\n",
        " \n",
        "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "max_seq_length = 128 #최장 토큰 길이"
      ],
      "metadata": {
        "id": "fIdZFubZ56gS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEl89K4J-hsF",
        "outputId": "cc4d4b60-f891-41a6-92bc-e6a25780a3f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 로드\n",
        "train_df = pd.read_csv('/content/drive/My Drive/VAIV/BERT/train/train.csv', index_col='id')\n",
        "val_df = pd.read_csv('/content/drive/My Drive/VAIV/BERT/valid/valid.csv', index_col='id')\n",
        "test_df = pd.read_csv('/content/drive/My Drive/VAIV/BERT/test/test.csv', index_col='id')"
      ],
      "metadata": {
        "id": "YhzWYERU7m0F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder().fit(pd.concat([train_df['label'], val_df['label']]))\n",
        "#문자 label을 숫자로 encoding 시킨다."
      ],
      "metadata": {
        "id": "rlyfZfROC0Ae"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val, X_test = pd.concat([train_df['text'], val_df['text']]).values, test_df['text'].values"
      ],
      "metadata": {
        "id": "cIJi8gBrCuv5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_val = label_encoder.fit_transform(pd.concat([train_df['label'], val_df['label']]))\n",
        "#train data set에 대한 scaling"
      ],
      "metadata": {
        "id": "FXGl3r2sESBW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val,y_train_val, test_size=0.1, random_state=0, stratify = y_train_val\n",
        "        )\n",
        "#random state : data 분할 시 shuffle random seed\n",
        "#stratify : 지정한 data 분할 유지, 나누어진 데이터셋도 기존 클래스 비율과 같아야 함."
      ],
      "metadata": {
        "id": "4Fpg01CdFUTQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = X_train\n",
        "train_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]\n",
        "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
        "train_label = y_train\n",
        " \n",
        "val_text = X_val\n",
        "val_text = [' '.join(t.split()[0:max_seq_length]) for t in val_text]\n",
        "val_text = np.array(val_text, dtype=object)[:, np.newaxis]\n",
        "val_label = y_val\n",
        " \n",
        "test_text = X_test\n",
        "test_text = [' '.join(t.split()[0:max_seq_length]) for t in test_text]\n",
        "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
        "\n",
        "#join 하는 부분은 max_seq_length를 넘는 token값을 제거하기 위한 수단\n",
        "#np.newaxis는 차원을 하나 추가하는 방법인데 train_text[0]으로 출력하면 dtype이, [0][0]으로 출력하면 string만 나오게끔 설정됨 (1차 => 2차원)\n",
        "\n",
        "#아무튼 위의 과정들은 다 전처리 관련한 것임 (scaling, max_token 넘는거 빼기, 파일 형식 바꿔주기 등등)"
      ],
      "metadata": {
        "id": "1A6XDQQeF08i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xixByFEqMMLm",
        "outputId": "21d908ae-f7f5-4547-dbbd-a220a3ce4e20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I got this as a supplement for skin and coat for my dogs. I couldn't tell a differenceat all in their coat or shedding.My mom used the remainder for her dogs and said it did seem to keep fleas off.\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook #진행률 모듈인 듯??\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wECwYKn-H9Nj",
        "outputId": "afbc818e-01d5-48f9-c60c-ffbc81af888a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertLayer(Layer):\n",
        "    \n",
        "    def __init__(self, n_fine_tune_layers=10, tf_hub = None, output_representation = 'pooled_output', trainable = False, **kwargs):\n",
        "        \n",
        "        self.n_fine_tune_layers = n_fine_tune_layers\n",
        "        self.is_trainble = trainable\n",
        "        self.output_size = 768\n",
        "        self.tf_hub = tf_hub\n",
        "        self.output_representation = output_representation\n",
        "        self.supports_masking = True\n",
        "        \n",
        "        super(BertLayer, self).__init__(**kwargs)\n",
        " \n",
        "    def build(self, input_shape):\n",
        " \n",
        "        self.bert = hub.Module(\n",
        "            self.tf_hub,\n",
        "            trainable=self.is_trainble,\n",
        "            name=\"{}_module\".format(self.name)\n",
        "        )\n",
        "        \n",
        "        \n",
        "        variables = list(self.bert.variable_map.values())\n",
        "        if self.is_trainble:\n",
        "            # 1 first remove unused layers\n",
        "            trainable_vars = [var for var in variables if not \"/cls/\" in var.name]\n",
        "            \n",
        "            \n",
        "            if self.output_representation == \"sequence_output\" or self.output_representation == \"mean_pooling\":\n",
        "                # 1 first remove unused pooled layers\n",
        "                trainable_vars = [var for var in trainable_vars if not \"/pooler/\" in var.name]\n",
        "                \n",
        "            # Select how many layers to fine tune\n",
        "            trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
        "            \n",
        "            # Add to trainable weights\n",
        "            for var in trainable_vars:\n",
        "                self._trainable_weights.append(var)\n",
        " \n",
        "            # Add non-trainable weights\n",
        "            for var in self.bert.variables:\n",
        "                if var not in self._trainable_weights:\n",
        "                    self._non_trainable_weights.append(var)\n",
        "                \n",
        "        else:\n",
        "             for var in variables:\n",
        "                self._non_trainable_weights.append(var)\n",
        "                \n",
        " \n",
        "        super(BertLayer, self).build(input_shape)\n",
        " \n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        \n",
        "        if self.output_representation == 'sequence_output':\n",
        "            inputs = [K.cast(x, dtype=\"bool\") for x in inputs]\n",
        "            mask = inputs[1]\n",
        "            \n",
        "            return mask\n",
        "        else:\n",
        "            return None\n",
        "        \n",
        "        \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.output_representation == \"sequence_output\":\n",
        "            return (input_shape[0][0], input_shape[0][1], self.output_size)\n",
        "        else:\n",
        "            return (input_shape[0][0], self.output_size)"
      ],
      "metadata": {
        "id": "dwlNctx1IswT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        " \n",
        "def build_model(max_seq_length, tf_hub, n_classes, n_fine_tune): \n",
        "    in_id = keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\") #token단위\n",
        "    in_mask = keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
        "    in_segment = keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "    \n",
        "    bert_output = BertLayer(n_fine_tune_layers=n_fine_tune, tf_hub = tf_hub, output_representation = 'mean_pooling', trainable = True)(bert_inputs)\n",
        "    drop = keras.layers.Dropout(0.3)(bert_output)\n",
        "    dense = keras.layers.Dense(256, activation='sigmoid')(drop)\n",
        "    drop = keras.layers.Dropout(0.3)(dense)\n",
        "    dense = keras.layers.Dense(64, activation='sigmoid')(drop)\n",
        "    pred = keras.layers.Dense(n_classes, activation='softmax')(dense)\n",
        "    \n",
        "    model = keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "    Adam = keras.optimizers.Adam(lr = 0.0005)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam, metrics=['sparse_categorical_accuracy'])\n",
        "    model.summary()\n",
        " \n",
        "    return model"
      ],
      "metadata": {
        "id": "H_f9OpZsJ_Fz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_vars(sess):\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    K.set_session(sess)\n",
        "n_classes = len(label_encoder.classes_)\n",
        "n_fine_tune_layers = 48\n",
        "n_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn0pH2btKOv4",
        "outputId": "734b59e2-87a4-446d-bfc1-cae6b32aeb0a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(max_seq_length, bert_path, n_classes, n_fine_tune_layers)\n",
        " \n",
        "# Instantiate variables\n",
        "initialize_vars(sess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "y0t5w7K4o3G7",
        "outputId": "9fabd749-5fcb-4cfa-d92c-3efc613607eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-855af911ec74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fine_tune_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Instantiate variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minitialize_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-c5d62e5da7c7>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(max_seq_length, tf_hub, n_classes, n_fine_tune)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbert_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0min_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_segment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_fine_tune_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fine_tune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_hub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_hub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean_pooling'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m                                    \u001b[0minput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                                    arguments=user_kwargs)\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;31m# Apply activity regularizer if any:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[0;34m(self, input_tensors, output_tensors, input_masks, output_masks, input_shapes, output_shapes, arguments)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Update tensor history, _keras_shape and _uses_learning_phase.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m             uses_lp = any(\n\u001b[1;32m    599\u001b[0m                 [getattr(x, '_uses_learning_phase', False)\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GBXXWEOjJfK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cNOGeCUlIp9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9jvTJOWYFYcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J-htLx_GEWB8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}